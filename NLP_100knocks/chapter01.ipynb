{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["◆参考\n","\n","自然言語処理100本ノック：https://nlp100.github.io/ja/ch01.html\n","\n","答え：https://github.com/yamaru12345/nlp100"],"metadata":{"id":"5I-_9b_Igwb4"}},{"cell_type":"markdown","metadata":{"id":"TF5HIiXoTzry"},"source":["# 第1章: 準備運動"]},{"cell_type":"markdown","metadata":{"id":"T7HtwX4XT4zc"},"source":["## 00. 文字列の逆順\n","***\n","文字列”stressed”の文字を逆に（末尾から先頭に向かって）並べた文字列を得よ．"]},{"cell_type":"code","metadata":{"id":"XlSePvcDT3JH","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ccb50110-a374-4bdc-a703-6e514c0d5b33","executionInfo":{"status":"ok","timestamp":1705988619778,"user_tz":-540,"elapsed":11,"user":{"displayName":"安富燦希","userId":"11033130310553545755"}}},"source":["str = 'stressed'\n","ans = str[::-1]\n","\n","print(ans)"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["desserts\n"]}]},{"cell_type":"markdown","metadata":{"id":"znMoAECvUV6s"},"source":["## 01. 「パタトクカシーー」\n","***\n","「パタトクカシーー」という文字列の1,3,5,7文字目を取り出して連結した文字列を得よ．"]},{"cell_type":"code","metadata":{"id":"Ivyu57SAUEZP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"da515a7d-88fb-43c4-dff6-8458b3b2c86a","executionInfo":{"status":"ok","timestamp":1705988619778,"user_tz":-540,"elapsed":10,"user":{"displayName":"安富燦希","userId":"11033130310553545755"}}},"source":["str = 'パタトクカシーー'\n","ans = str[::2]\n","\n","print(ans)"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["パトカー\n"]}]},{"cell_type":"markdown","metadata":{"id":"q03ZjV4jVDPd"},"source":["## 02. 「パトカー」＋「タクシー」＝「パタトクカシーー」\n","***\n","「パトカー」＋「タクシー」の文字を先頭から交互に連結して文字列「パタトクカシーー」を得よ．"]},{"cell_type":"code","metadata":{"id":"KsPQn6eXUgaF","colab":{"base_uri":"https://localhost:8080/"},"outputId":"05705815-3f64-4b83-c8ac-0b84ed0ed279","executionInfo":{"status":"ok","timestamp":1705988619778,"user_tz":-540,"elapsed":9,"user":{"displayName":"安富燦希","userId":"11033130310553545755"}}},"source":["str1 = 'パトカー'\n","str2 = 'タクシー'\n","ans = ''.join([i + j for i, j in zip(str1, str2)])\n","\n","print(ans)\n","\n","reference_1 = [i + j for i, j in zip(str1, str2)]\n","\n","print(reference_1)\n","\n","reference_2 = 'and'.join([i + j for i, j in zip(str1, str2)])\n","\n","print(reference_2)"],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["パタトクカシーー\n","['パタ', 'トク', 'カシ', 'ーー']\n","パタandトクandカシandーー\n"]}]},{"cell_type":"markdown","source":["    zip(str1, str2): zip 関数は、2つ以上のシーケンス（ここでは文字列）から要素を1つずつ取り出して組み合わせるイテレータを生成します。\n","    この場合、str1 と str2 の対応する位置の文字を順番に組み合わせます。\n","\n","    [i + j for i, j in zip(str1, str2)]: リスト内包表記を使用して、zip で取得した対応する位置の文字を交互に組み合わせて新しいリストを生成します。\n","    各文字列の同じ位置の文字を連結しています。\n","\n","    [''.join(...): join メソッドを使用して、リスト内の文字列を連結して新しい文字列を生成します。\n","    ここでは、空の文字列 '' で各要素を結合しています"],"metadata":{"id":"habfugjSkLDt"}},{"cell_type":"markdown","metadata":{"id":"88tWD10wWrG_"},"source":["## 03. 円周率\n","***\n","“Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.”という文を単語に分解し，各単語の（アルファベットの）文字数を先頭から出現順に並べたリストを作成せよ．"]},{"cell_type":"code","metadata":{"id":"z5Lq8GfdVaVI","colab":{"base_uri":"https://localhost:8080/"},"outputId":"00724191-0c21-4d09-c458-6b98ee036f16","executionInfo":{"status":"ok","timestamp":1705988619778,"user_tz":-540,"elapsed":8,"user":{"displayName":"安富燦希","userId":"11033130310553545755"}}},"source":["import re\n","\n","str = 'Now I need a drink, alcoholic of course, after the heavy lectures involving quantum mechanics.'\n","str = re.sub('[,\\.]', '', str)  # ,と.を除去\n","splits = str.split()  # スペースで区切って単語ごとのリストを作成\n","ans = [len(i) for i in splits]\n","\n","print(ans)\n","\n","print(str)\n","print(splits)"],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["[3, 1, 4, 1, 5, 9, 2, 6, 5, 3, 5, 8, 9, 7, 9]\n","Now I need a drink alcoholic of course after the heavy lectures involving quantum mechanics\n","['Now', 'I', 'need', 'a', 'drink', 'alcoholic', 'of', 'course', 'after', 'the', 'heavy', 'lectures', 'involving', 'quantum', 'mechanics']\n"]}]},{"cell_type":"markdown","source":["    re.sub('[,\\.]', '', str): 正規表現を使用して、文字列 str 中の , と . を削除します。re.sub は置換を行うための正規表現操作を提供します。\n","    [,\\.] は , または . にマッチし、それらの文字を空文字に置換しています。\n","\n","    str.split(): split メソッドを使用して、文字列 str をスペースで区切り、単語ごとのリスト splits を作成します。\n","    \n","    [len(i) for i in splits]: リスト内包表記を使用して、splits 中の各単語の文字数を計算し、それらの文字数からなる新しいリスト ans を生成します。"],"metadata":{"id":"6tMESXEbm564"}},{"cell_type":"markdown","metadata":{"id":"vpZfX1v8OHRk"},"source":["## 04. 元素記号\n","***\n","“Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.”という文を単語に分解し，1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語は先頭の1文字，それ以外の単語は先頭に2文字を取り出し，取り出した文字列から単語の位置（先頭から何番目の単語か）への連想配列（辞書型もしくはマップ型）を作成せよ．"]},{"cell_type":"code","metadata":{"id":"4qloDpQOXDPP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f4ddfe84-4afd-4175-84e4-6bb13a127739","executionInfo":{"status":"ok","timestamp":1705988619778,"user_tz":-540,"elapsed":7,"user":{"displayName":"安富燦希","userId":"11033130310553545755"}}},"source":["str = 'Hi He Lied Because Boron Could Not Oxidize Fluorine. New Nations Might Also Sign Peace Security Clause. Arthur King Can.'\n","splits = str.split()\n","one_ch = [1, 5, 6, 7, 8, 9, 15, 16, 19]  # 1文字を取り出す単語の番号リスト\n","ans = {}\n","for i, word in enumerate(splits):\n","  if i + 1 in one_ch:\n","    ans[word[:1]] = i + 1  # リストにあれば1文字を取得\n","  else:\n","    ans[word[:2]] = i + 1  # なければ2文字を取得\n","\n","print(ans)\n","\n","print(splits)"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["{'H': 1, 'He': 2, 'Li': 3, 'Be': 4, 'B': 5, 'C': 6, 'N': 7, 'O': 8, 'F': 9, 'Ne': 10, 'Na': 11, 'Mi': 12, 'Al': 13, 'Si': 14, 'P': 15, 'S': 16, 'Cl': 17, 'Ar': 18, 'K': 19, 'Ca': 20}\n","['Hi', 'He', 'Lied', 'Because', 'Boron', 'Could', 'Not', 'Oxidize', 'Fluorine.', 'New', 'Nations', 'Might', 'Also', 'Sign', 'Peace', 'Security', 'Clause.', 'Arthur', 'King', 'Can.']\n"]}]},{"cell_type":"markdown","source":["    str.split(): 文を単語ごとに分割し、単語のリスト splits を得ます。\n","    one_ch: 1文字だけ取り出す単語の位置を指定したリストです。この例では、1, 5, 6, 7, 8, 9, 15, 16, 19番目の単語を1文字だけ取り出します。\n","    enumerate(splits): splits リストの各単語に対して、その単語と同時にインデックス（位置）を取得します。\n","    for i, word in enumerate(splits):: 各単語とその位置に対してループを実行します。\n","    if i + 1 in one_ch:: もし単語の位置が one_ch リストに含まれている場合（1文字だけ取り出す単語の場合）:\n","    ans[word[:1]] = i + 1: 辞書 ans に、その単語の先頭1文字をキーとし、その位置（インデックス + 1）を値として追加します。\n","    else:: それ以外の場合（2文字取り出す単語の場合）:\n","    ans[word[:2]] = i + 1: 辞書 ans に、その単語の先頭2文字をキーとし、その位置（インデックス + 1）を値として追加します。"],"metadata":{"id":"KptobQOGoOHR"}},{"cell_type":"markdown","metadata":{"id":"EYNvyOUCOJru"},"source":["## 05. n-gram\n","***\n","与えられたシーケンス（文字列やリストなど）からn-gramを作る関数を作成せよ．この関数を用い，”I am an NLPer”という文から単語bi-gram，文字bi-gramを得よ．"]},{"cell_type":"code","metadata":{"id":"5ebjTpjDON4B","colab":{"base_uri":"https://localhost:8080/"},"outputId":"9591488e-be5f-46c0-ba7c-6a76bf0b1273","executionInfo":{"status":"ok","timestamp":1705988619778,"user_tz":-540,"elapsed":6,"user":{"displayName":"安富燦希","userId":"11033130310553545755"}}},"source":["def ngram(n, lst):\n","    return list(zip(*[lst[i:] for i in range(n)]))\n","\n","str = 'I am an NLPer'\n","words_bi_gram = ngram(2, str.split())\n","chars_bi_gram = ngram(2, str)\n","\n","print('単語bi-gram:', words_bi_gram)\n","print('文字bi-gram:', chars_bi_gram)"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["単語bi-gram: [('I', 'am'), ('am', 'an'), ('an', 'NLPer')]\n","文字bi-gram: [('I', ' '), (' ', 'a'), ('a', 'm'), ('m', ' '), (' ', 'a'), ('a', 'n'), ('n', ' '), (' ', 'N'), ('N', 'L'), ('L', 'P'), ('P', 'e'), ('e', 'r')]\n"]}]},{"cell_type":"code","source":["for i in range(2):\n","    print(i)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NMRrzUx7yVZv","executionInfo":{"status":"ok","timestamp":1705988619778,"user_tz":-540,"elapsed":5,"user":{"displayName":"安富燦希","userId":"11033130310553545755"}},"outputId":"6c315f3e-491c-4a60-aa15-3756a18205c1"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["0\n","1\n"]}]},{"cell_type":"code","source":["# reference\n","def ngram_reference(n, lst):\n","    return list([lst[i:] for i in range(n)])\n","\n","str = 'I am an NLPer'\n","words_bi_gram_reference = ngram_reference(2, str.split())\n","chars_bi_gram_reference = ngram_reference(2, str)\n","\n","print('単語bi-gram:', words_bi_gram_reference)\n","print('文字bi-gram:', chars_bi_gram_reference)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Pt3G68OysTn3","executionInfo":{"status":"ok","timestamp":1705988619779,"user_tz":-540,"elapsed":6,"user":{"displayName":"安富燦希","userId":"11033130310553545755"}},"outputId":"eeb98387-93bf-467f-8681-4e5994350a25"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["単語bi-gram: [['I', 'am', 'an', 'NLPer'], ['am', 'an', 'NLPer']]\n","文字bi-gram: ['I am an NLPer', ' am an NLPer']\n"]}]},{"cell_type":"code","source":["str.split()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Jcs_hYqgtZkf","executionInfo":{"status":"ok","timestamp":1705988620319,"user_tz":-540,"elapsed":545,"user":{"displayName":"安富燦希","userId":"11033130310553545755"}},"outputId":"8a15e50a-0a7c-4046-ba38-7894ad76a225"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['I', 'am', 'an', 'NLPer']"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":["str = 'I am an NLPer'\n","[str[i:] for i in range(2)]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sjJzQY16tZmU","executionInfo":{"status":"ok","timestamp":1705988620319,"user_tz":-540,"elapsed":7,"user":{"displayName":"安富燦希","userId":"11033130310553545755"}},"outputId":"0a11f9ad-858d-426c-f38a-e57cb2c1c4b7"},"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['I am an NLPer', ' am an NLPer']"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["    ngram 関数:\n","    n: 生成するn-gramのnを指定します。\n","    lst: n-gramを生成する対象のリスト（文字列または単語リスト）です。\n","    lst[i:] により、リスト lst のインデックス i から末尾までの部分リストを作成します。\n","    [lst[i:] for i in range(n)] により、n個の部分リストを生成します。\n","    zip(*...) はこれらの部分リストをまとめ、それぞれの要素をタプルとして取得します。\n","    list(...) により、タプルのリストを作成して返します。\n","\n","    テキストデータの準備:\n","    str = 'I am an NLPer' は処理対象のテキストデータです。\n","\n","    単語bi-gram:\n","    words_bi_gram = ngram(2, str.split()): スペースで単語に分割された単語リストに対して、単語bi-gramを生成します。\n","\n","    文字bi-gram:\n","    chars_bi_gram = ngram(2, str): 文字列に対して、文字bi-gramを生成します。"],"metadata":{"id":"AweKmITvp3AV"}},{"cell_type":"markdown","source":["    「シーケンス」とは、順序を持った要素の列を指します。Pythonにおいて、文字列（str型）もまたシーケンスの一種です。例として、以下の文字列を考えてみましょう。\n","\n","    str = 'I am an NLPer'\n","\n","    この文字列 str は、文字 'I'、空白、'a'、'm'、空白、'a'、'n'、空白、'N'、'L'、'P'、'e'、'r' の順に要素を持つシーケンスです。\n","    シーケンスは、要素の順序が重要であり、それぞれの要素は固有の位置（インデックス）を持っています。\n","    例えば、str のインデックス 0 の要素は 'I' であり、インデックス 2 の要素は空白です。\n","    シーケンスには文字列以外にも、リストやタプルも含まれます。\n","    これらも同様に、要素が順序を持ち、各要素にはインデックスが割り振られています。\n","    シーケンスは、プログラムでデータを処理する際に頻繁に使用される重要なデータ構造の一つです。"],"metadata":{"id":"r-8TY8E_plsi"}},{"cell_type":"markdown","source":["\n","    n-gram（エングラム）は、テキストデータや系列データを連続したn個の要素（文字、単語、または他のトークン）に分割する手法です。以下に具体例を挙げて説明します。\n","\n","    文字n-gramの例 (Character n-gram):\n","\n","    例えば、文字列 \"Hello\" からの2-gramを取る場合：\n","    Input: \"Hello\"\n","    2-gram: ['H', 'e', 'l', 'l', 'o']\n","    \n","    この場合、2-gramは連続する2つの文字の組み合わせを示しています。最初の2-gramは 'H' と 'e'、次は 'e' と 'l'、そして最後は 'o' と 'l' です。\n","\n","    単語n-gramの例 (Word n-gram):\n","    同様に、単語レベルの3-gramを取る場合：\n","    Input: \"This is an example\"\n","    3-gram: ['This', 'is', 'an', 'example']\n","    \n","    ここでは、各3-gramは3つの連続する単語を表しています。最初の3-gramは 'This', 'is', 'an'、次は 'is', 'an', 'example' です。\n","\n","    応用例: 自然言語処理 (NLP):\n","    NLPでは、n-gramはテキストデータの特徴量抽出や言語モデリングに広く使用されます。\n","    例えば、2-gramや3-gramを用いて文章の特徴量を作成することで、文章中の単語やフレーズの関連性を把握できます。\n","\n","    例:Input: \"Natural language processing is fascinating\"\n","    2-gram: ['Natural language', 'language processing', 'processing is', 'is fascinating']\n","    \n","    この場合、2-gramは2つの単語から成るフレーズを示しており、文章の局所的な構造を把握する手助けとなります。"],"metadata":{"id":"qELttP7_qpOp"}},{"cell_type":"markdown","metadata":{"id":"dLPmmHDiOOf6"},"source":["## 06. 集合\n","***\n","“paraparaparadise”と”paragraph”に含まれる文字bi-gramの集合を，それぞれ, XとYとして求め，XとYの和集合，積集合，差集合を求めよ．さらに，’se’というbi-gramがXおよびYに含まれるかどうかを調べよ．"]},{"cell_type":"code","metadata":{"id":"oruJ1b7SOR99","colab":{"base_uri":"https://localhost:8080/"},"outputId":"a5877e82-be66-4df9-daed-2a373f701d86","executionInfo":{"status":"ok","timestamp":1705988620319,"user_tz":-540,"elapsed":7,"user":{"displayName":"安富燦希","userId":"11033130310553545755"}}},"source":["str1 = 'paraparaparadise'\n","str2 = 'paragraph'\n","X = set(ngram(2, str1))\n","Y = set(ngram(2, str2))\n","union = X | Y\n","intersection = X & Y\n","difference = X - Y\n","\n","print('X:', X)\n","print('Y:', Y)\n","print('和集合:', union)\n","print('積集合:', intersection)\n","print('差集合:', difference)\n","print('Xにseが含まれるか:', {('s', 'e')} <= X)\n","print('Yにseが含まれるか:', {('s', 'e')} <= Y)\n","\n","# reference\n","print('Xの集合とseの集合は同じか:', {('s', 'e')} == X)\n","print('Yの集合とseの集合は同じか:', {('s', 'e')} == Y)"],"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["X: {('p', 'a'), ('a', 'r'), ('r', 'a'), ('a', 'p'), ('d', 'i'), ('s', 'e'), ('i', 's'), ('a', 'd')}\n","Y: {('p', 'a'), ('a', 'r'), ('r', 'a'), ('a', 'p'), ('p', 'h'), ('a', 'g'), ('g', 'r')}\n","和集合: {('p', 'a'), ('a', 'r'), ('r', 'a'), ('a', 'p'), ('d', 'i'), ('p', 'h'), ('a', 'g'), ('s', 'e'), ('i', 's'), ('g', 'r'), ('a', 'd')}\n","積集合: {('p', 'a'), ('a', 'p'), ('a', 'r'), ('r', 'a')}\n","差集合: {('s', 'e'), ('i', 's'), ('a', 'd'), ('d', 'i')}\n","Xにseが含まれるか: True\n","Yにseが含まれるか: False\n","Xの集合とseの集合は同じか: False\n","Yの集合とseの集合は同じか: False\n"]}]},{"cell_type":"markdown","source":["    print('Xにseが含まれるか:', {('s', 'e')} <= X)とprint('Xにseが含まれるか:', {('s', 'e')} == X)の違い\n","\n","    <= 演算子: 集合 A が集合 B を部分集合として含む場合に True を返します。\n","    == 演算子: 集合 A と集合 B が等しい場合に True を返します。\n","\n","    したがって、{('s', 'e')} <= X は、集合 X が {('s', 'e')} を部分集合として含むかを確認しています。\n","    一方で、{('s', 'e')} == X は、集合 X が {('s', 'e')} と等しいかを確認しています。\n","    部分集合の場合、他にも要素が存在しても構いませんが、等しい場合は両者が完全に同じである必要があります。"],"metadata":{"id":"KDK2rMvjvOvJ"}},{"cell_type":"markdown","source":["    和集合（Union）、積集合（Intersection）、差集合（Difference）は、集合論において重要な概念です。以下にそれぞれの操作について具体例を挙げて説明します。\n","\n","    和集合（Union）:\n","    和集合は、2つの集合の要素すべてを含む新しい集合を作成する操作です。\n","\n","    例:\n","    X = {1, 2, 3}\n","    Y = {3, 4, 5}\n","\n","    和集合 X ∪ Y: {1, 2, 3, 4, 5}\n","    和集合は、XとYの両方に存在する重複する要素を1回だけ含んでいます。\n","\n","    積集合（Intersection）:\n","    積集合は、2つの集合の共通の要素からなる新しい集合を作成する操作です。\n","\n","    例:\n","    X = {1, 2, 3}\n","    Y = {3, 4, 5}\n","\n","    積集合 X ∩ Y: {3}\n","    積集合には、XとYの両方に存在する共通の要素が含まれます。\n","\n","    差集合（Difference）:\n","    差集合は、1つの集合から他の集合の要素を取り除いた新しい集合を作成する操作です。\n","\n","    例:\n","    X = {1, 2, 3}\n","    Y = {3, 4, 5}\n","\n","    X - Y (Xの差集合Y): {1, 2}\n","    Y - X (Yの差集合X): {4, 5}\n","    X - Y は、Xには含まれていてYには含まれていない要素からなります。同様に、Y - X は、Yには含まれていてXには含まれていない要素からなります。\n","\n","    これらの集合演算は、集合論を基にした数学的な操作であり、データ処理やデータ分析、データベースなどの分野で頻繁に使用されます。"],"metadata":{"id":"CqDIx4sduoXk"}},{"cell_type":"markdown","metadata":{"id":"7D_kaglGOSgL"},"source":["## 07. テンプレートによる文生成\n","***\n","引数x, y, zを受け取り「x時のyはz」という文字列を返す関数を実装せよ．さらに，x=12, y=”気温”, z=22.4として，実行結果を確認せよ．"]},{"cell_type":"code","metadata":{"id":"nTBSpT7VOVw6","colab":{"base_uri":"https://localhost:8080/"},"outputId":"f8558e96-3860-4b3e-ef37-d6fa09a270f4","executionInfo":{"status":"ok","timestamp":1705988620319,"user_tz":-540,"elapsed":6,"user":{"displayName":"安富燦希","userId":"11033130310553545755"}}},"source":["def generate_sentence(x, y, z):\n","  print(f'{x}時のとき{y}は{z}')\n","\n","generate_sentence(12, '気温', 22.4)"],"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["12時のとき気温は22.4\n"]}]},{"cell_type":"markdown","metadata":{"id":"CZEogrN2OWXN"},"source":["## 08. 暗号文\n","***\n","与えられた文字列の各文字を，以下の仕様で変換する関数cipherを実装せよ．\n","\n","英小文字ならば(219 - 文字コード)の文字に置換\n","その他の文字はそのまま出力\n","この関数を用い，英語のメッセージを暗号化・復号化せよ．"]},{"cell_type":"code","metadata":{"id":"9djc4p0rOaMY","colab":{"base_uri":"https://localhost:8080/"},"outputId":"027fba34-802f-4530-bddb-c4909a56d833","executionInfo":{"status":"ok","timestamp":1705988620320,"user_tz":-540,"elapsed":6,"user":{"displayName":"安富燦希","userId":"11033130310553545755"}}},"source":["def cipher(str):\n","  rep = [chr(219 - ord(x)) if x.islower() else x for x in str]\n","\n","  return ''.join(rep)\n","\n","message = 'the quick brown fox jumps over the lazy dog'\n","message = cipher(message)\n","print('暗号化:', message)\n","message = cipher(message)\n","print('復号化:', message)"],"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["暗号化: gsv jfrxp yildm ulc qfnkh levi gsv ozab wlt\n","復号化: the quick brown fox jumps over the lazy dog\n"]}]},{"cell_type":"markdown","source":["    リスト内包表記を使用して文字列 str の各文字をシーザー暗号で暗号化する処理を行っています。具体的には、アルファベットの小文字に対しては、文字を逆さまにするように暗号化が行われます。それ以外の文字（大文字や記号など）はそのまま残ります。\n","\n","    以下に、この行の各要素について詳しく説明します：\n","\n","    chr(219 - ord(x)): 文字 x の ASCII コードを取得し、それを 219 から引いた後、その結果の ASCII コードに対応する文字に変換します。\n","    これにより、小文字アルファベットが逆さまになります。例えば、'a' が 'z' に、'b' が 'y' に変換されます。\n","\n","    if x.islower() else x: 文字 x が小文字かどうかを確認し、小文字の場合にはシーザー暗号で暗号化を行います。それ以外の場合は、文字をそのまま残します。\n","\n","    リスト内包表記により、文字列 str 中の各文字に対して上記の操作を行い、結果をリスト rep に格納します。\n","\n","    ''.join(rep): リスト rep の各要素を空文字を使って結合し、暗号化された文字列を得ます。\n","    \n","    この行を実行することで、与えられた文字列の小文字のアルファベットが逆さまになるように暗号化されたリストが生成されます。"],"metadata":{"id":"eJeio_C2xiDq"}},{"cell_type":"markdown","metadata":{"id":"ckhSP3jLOatq"},"source":["## 09. Typoglycemia\n","***\n","スペースで区切られた単語列に対して，各単語の先頭と末尾の文字は残し，それ以外の文字の順序をランダムに並び替えるプログラムを作成せよ．ただし，長さが４以下の単語は並び替えないこととする．適当な英語の文（例えば”I couldn’t believe that I could actually understand what I was reading : the phenomenal power of the human mind .”）を与え，その実行結果を確認せよ．"]},{"cell_type":"code","metadata":{"id":"d2SFfgGiOeWP","colab":{"base_uri":"https://localhost:8080/"},"outputId":"09073ec7-fe28-4ca2-da2f-f0efe5a270de","executionInfo":{"status":"ok","timestamp":1705988620320,"user_tz":-540,"elapsed":5,"user":{"displayName":"安富燦希","userId":"11033130310553545755"}}},"source":["import random\n","\n","def shuffle(words):\n","  result = []\n","  for word in words.split():\n","    if len(word) > 4:  # 長さが4超であればシャッフル\n","      word = word[:1] + ''.join(random.sample(word[1:-1], len(word) - 2)) + word[-1:]\n","    result.append(word)\n","\n","  return ' '.join(result)\n","\n","words = \"I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\"\n","ans = shuffle(words)\n","\n","print(ans)"],"execution_count":14,"outputs":[{"output_type":"stream","name":"stdout","text":["I clduno't beevlie that I could aclulaty unneadtsrd what I was rdineag : the pehonamnel peowr of the haumn mind .\n"]}]},{"cell_type":"code","source":["test_1 = words[:1]\n","test_2 = ''.join(random.sample(words[1:-1], len(words) - 2))\n","test_3 = words[1:-1]\n","test_4 = len(words) - 2\n","test_5 = random.sample(words[1:-1], len(words) - 2)\n","test_6 = words[-1:]\n","\n","print(\"words:\", words)\n","print(\"test_1:\", test_1)\n","print(\"test_2:\", test_2)\n","print(\"test_3:\", test_3)\n","print(\"test_4:\", test_4)\n","print(\"test_5:\", test_5)\n","print(\"test_6:\", test_6)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"poxmKaac0KO7","executionInfo":{"status":"ok","timestamp":1705988620320,"user_tz":-540,"elapsed":4,"user":{"displayName":"安富燦希","userId":"11033130310553545755"}},"outputId":"a8d82290-9ba9-4289-f318-8331f222f020"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["words: I couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind .\n","test_1: I\n","test_2:  etdwnwahe v u odmhs b uhuietulImeeihytn fduna apa 'cnnd lenadt rtto nwaeh sralec :tpolIraidl   lnmh  teo gaeco\n","test_3:  couldn't believe that I could actually understand what I was reading : the phenomenal power of the human mind \n","test_4: 111\n","test_5: ['t', 'o', ' ', 't', ' ', 'n', 'l', ' ', 'b', 'm', 'o', 'h', ' ', 'm', ' ', 'n', ' ', 'h', 'd', ' ', 's', 'o', 'p', ':', 'h', 'i', 'e', 'i', 'I', 'u', ' ', ' ', 'l', 'y', 'n', 'o', 'e', 'l', 'e', 'a', 't', 'r', 'o', 'e', ' ', 'n', 't', ' ', 'a', 'l', ' ', 'd', 'a', 'n', 'i', ' ', 'h', ' ', 'a', 'f', 'a', 't', 'r', 'a', 'd', \"'\", 'n', 'u', 'a', 't', 'a', 'w', 'n', ' ', 't', ' ', 'c', 'm', 'e', 'v', 'e', 'h', 'c', 'd', 'h', 'n', 'l', ' ', 'e', 'u', 'w', 'e', 's', 'a', 'u', 'e', 't', 'd', 'd', 'u', 'c', ' ', ' ', 'I', 'r', 'p', 'g', 'l', ' ', 'e', 'w']\n","test_6: .\n"]}]},{"cell_type":"markdown","source":["    この関数 shuffle は、与えられた文字列 words を単語ごとに分割し、各単語が特定の条件を満たす場合にその単語をシャッフル（ランダムな順番に並び替え）します。\n","    最終的に、シャッフルされた単語を含む文字列を返します。\n","\n","    具体的な動作は以下の通りです：\n","    for word in words.split():: 入力された文字列 words を空白で分割し、各単語に対してループを行います。\n","    if len(word) > 4:: 単語の長さが4よりも長い場合に以下の処理を行います。\n","    word[:1]: 単語の最初の文字を取得します。\n","    word[1:-1]: 単語の2番目から最後から1つ手前までの部分を取得します。\n","    random.sample(word[1:-1], len(word) - 2): 単語の2番目から最後から1つ手前までの部分をランダムにシャッフルします。\n","    word[-1:]: 単語の最後の文字を取得します。\n","    word[:1] + ''.join(...) + word[-1:]: 上記の結果を組み合わせて、単語の最初の文字 + シャッフルされた部分 + 最後の文字 となります。\n","    result.append(word): 上記の処理で変換された単語をリスト result に追加します。\n","    return ' '.join(result): リスト内の単語を空白で結合し、シャッフルされた文字列を返します。\n","\n","    この関数は、指定の条件を満たす単語のみをシャッフルするという独自の文字列変換を行うものです。たとえば、'This is a sample sentence' という文字列が与えられた場合、長さが4よりも長い単語がランダムにシャッフルされて返されるでしょう。"],"metadata":{"id":"TgdaKSPyz0Gx"}}]}