{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ZP8aiki_I-LD"},"source":["# 第5章: 係り受け解析\n","日本語Wikipediaの「人工知能」に関する記事からテキスト部分を抜き出したファイルがai.ja.zipに収録されている． この文章をCaboChaやKNP等のツールを利用して係り受け解析を行い，その結果をai.ja.txt.parsedというファイルに保存せよ．このファイルを読み込み，以下の問に対応するプログラムを実装せよ．"]},{"cell_type":"code","metadata":{"id":"BXAqAX72JBdb","outputId":"3c27b5f3-8c27-447d-a7bc-8cd32b77f1dc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706097459603,"user_tz":-540,"elapsed":870,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["!wget https://nlp100.github.io/data/ai.ja.zip\n","!unzip ai.ja.zip"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-01-24 11:57:38--  https://nlp100.github.io/data/ai.ja.zip\n","Resolving nlp100.github.io (nlp100.github.io)... 185.199.108.153, 185.199.109.153, 185.199.110.153, ...\n","Connecting to nlp100.github.io (nlp100.github.io)|185.199.108.153|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 17516 (17K) [application/zip]\n","Saving to: ‘ai.ja.zip’\n","\n","ai.ja.zip           100%[===================>]  17.11K  --.-KB/s    in 0s      \n","\n","2024-01-24 11:57:38 (63.2 MB/s) - ‘ai.ja.zip’ saved [17516/17516]\n","\n","Archive:  ai.ja.zip\n","  inflating: ai.ja.txt               \n","  inflating: readme.ai.ja.md         \n"]}]},{"cell_type":"code","metadata":{"id":"GCzzzcjMKzEY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706097475726,"user_tz":-540,"elapsed":15384,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}},"outputId":"d7e3938b-a3e8-48db-961b-ab634b1c86bc"},"source":["!apt install mecab libmecab-dev mecab-ipadic-utf8"],"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","The following additional packages will be installed:\n","  libmecab2 mecab-ipadic mecab-utils\n","The following NEW packages will be installed:\n","  libmecab-dev libmecab2 mecab mecab-ipadic mecab-ipadic-utf8 mecab-utils\n","0 upgraded, 6 newly installed, 0 to remove and 30 not upgraded.\n","Need to get 7,367 kB of archives.\n","After this operation, 59.3 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmecab2 amd64 0.996-14build9 [199 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu jammy/main amd64 libmecab-dev amd64 0.996-14build9 [306 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu jammy/main amd64 mecab-utils amd64 0.996-14build9 [4,850 B]\n","Get:4 http://archive.ubuntu.com/ubuntu jammy/main amd64 mecab-ipadic all 2.7.0-20070801+main-3 [6,718 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu jammy/universe amd64 mecab amd64 0.996-14build9 [136 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu jammy/main amd64 mecab-ipadic-utf8 all 2.7.0-20070801+main-3 [4,384 B]\n","Fetched 7,367 kB in 2s (4,013 kB/s)\n","Selecting previously unselected package libmecab2:amd64.\n","(Reading database ... 121658 files and directories currently installed.)\n","Preparing to unpack .../0-libmecab2_0.996-14build9_amd64.deb ...\n","Unpacking libmecab2:amd64 (0.996-14build9) ...\n","Selecting previously unselected package libmecab-dev.\n","Preparing to unpack .../1-libmecab-dev_0.996-14build9_amd64.deb ...\n","Unpacking libmecab-dev (0.996-14build9) ...\n","Selecting previously unselected package mecab-utils.\n","Preparing to unpack .../2-mecab-utils_0.996-14build9_amd64.deb ...\n","Unpacking mecab-utils (0.996-14build9) ...\n","Selecting previously unselected package mecab-ipadic.\n","Preparing to unpack .../3-mecab-ipadic_2.7.0-20070801+main-3_all.deb ...\n","Unpacking mecab-ipadic (2.7.0-20070801+main-3) ...\n","Selecting previously unselected package mecab.\n","Preparing to unpack .../4-mecab_0.996-14build9_amd64.deb ...\n","Unpacking mecab (0.996-14build9) ...\n","Selecting previously unselected package mecab-ipadic-utf8.\n","Preparing to unpack .../5-mecab-ipadic-utf8_2.7.0-20070801+main-3_all.deb ...\n","Unpacking mecab-ipadic-utf8 (2.7.0-20070801+main-3) ...\n","Setting up libmecab2:amd64 (0.996-14build9) ...\n","Setting up libmecab-dev (0.996-14build9) ...\n","Setting up mecab-utils (0.996-14build9) ...\n","Setting up mecab-ipadic (2.7.0-20070801+main-3) ...\n","Compiling IPA dictionary for Mecab.  This takes long time...\n","reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n","emitting double-array: 100% |###########################################| \n","/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n","reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n","reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n","reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n","reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27328\n","reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n","reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n","reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n","reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n","reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n","reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n","reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n","reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n","reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n","reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n","reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n","reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n","reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n","reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n","reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n","reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n","reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n","reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n","reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n","reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","update-alternatives: using /var/lib/mecab/dic/ipadic to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n","Setting up mecab (0.996-14build9) ...\n","Compiling IPA dictionary for Mecab.  This takes long time...\n","reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n","emitting double-array: 100% |###########################################| \n","/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n","reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n","reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n","reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n","reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27328\n","reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n","reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n","reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n","reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n","reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n","reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n","reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n","reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n","reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n","reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n","reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n","reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n","reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n","reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n","reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n","reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n","reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n","reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n","reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n","reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","Setting up mecab-ipadic-utf8 (2.7.0-20070801+main-3) ...\n","Compiling IPA dictionary for Mecab.  This takes long time...\n","reading /usr/share/mecab/dic/ipadic/unk.def ... 40\n","emitting double-array: 100% |###########################################| \n","/usr/share/mecab/dic/ipadic/model.def is not found. skipped.\n","reading /usr/share/mecab/dic/ipadic/Noun.adjv.csv ... 3328\n","reading /usr/share/mecab/dic/ipadic/Noun.org.csv ... 16668\n","reading /usr/share/mecab/dic/ipadic/Noun.name.csv ... 34202\n","reading /usr/share/mecab/dic/ipadic/Noun.proper.csv ... 27328\n","reading /usr/share/mecab/dic/ipadic/Noun.number.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Adnominal.csv ... 135\n","reading /usr/share/mecab/dic/ipadic/Postp.csv ... 146\n","reading /usr/share/mecab/dic/ipadic/Suffix.csv ... 1393\n","reading /usr/share/mecab/dic/ipadic/Postp-col.csv ... 91\n","reading /usr/share/mecab/dic/ipadic/Filler.csv ... 19\n","reading /usr/share/mecab/dic/ipadic/Prefix.csv ... 221\n","reading /usr/share/mecab/dic/ipadic/Verb.csv ... 130750\n","reading /usr/share/mecab/dic/ipadic/Noun.demonst.csv ... 120\n","reading /usr/share/mecab/dic/ipadic/Symbol.csv ... 208\n","reading /usr/share/mecab/dic/ipadic/Others.csv ... 2\n","reading /usr/share/mecab/dic/ipadic/Auxil.csv ... 199\n","reading /usr/share/mecab/dic/ipadic/Interjection.csv ... 252\n","reading /usr/share/mecab/dic/ipadic/Adverb.csv ... 3032\n","reading /usr/share/mecab/dic/ipadic/Adj.csv ... 27210\n","reading /usr/share/mecab/dic/ipadic/Conjunction.csv ... 171\n","reading /usr/share/mecab/dic/ipadic/Noun.verbal.csv ... 12146\n","reading /usr/share/mecab/dic/ipadic/Noun.adverbal.csv ... 795\n","reading /usr/share/mecab/dic/ipadic/Noun.nai.csv ... 42\n","reading /usr/share/mecab/dic/ipadic/Noun.others.csv ... 151\n","reading /usr/share/mecab/dic/ipadic/Noun.place.csv ... 72999\n","reading /usr/share/mecab/dic/ipadic/Noun.csv ... 60477\n","emitting double-array: 100% |###########################################| \n","reading /usr/share/mecab/dic/ipadic/matrix.def ... 1316x1316\n","emitting matrix      : 100% |###########################################| \n","\n","done!\n","update-alternatives: using /var/lib/mecab/dic/ipadic-utf8 to provide /var/lib/mecab/dic/debian (mecab-dictionary) in auto mode\n","Processing triggers for man-db (2.10.2-1) ...\n","Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n","\n","/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n","\n"]}]},{"cell_type":"code","metadata":{"id":"jY0gYp3Uq_kZ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706097476123,"user_tz":-540,"elapsed":399,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}},"outputId":"01202a2f-4f4c-417c-f844-04cfce1ac03e"},"source":["FILE_ID = \"0B4y35FiV1wh7QVR6VXJ5dWExSTQ\"\n","FILE_NAME = \"crfpp.tar.gz\"\n","!wget 'https://docs.google.com/uc?export=download&id=$FILE_ID' -O $FILE_NAME\n","!tar xvf crfpp.tar.gz\n","%cd CRF++-0.58\n","!./configure && make && make install && ldconfig\n","%cd .."],"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-01-24 11:57:55--  https://docs.google.com/uc?export=download&id=$FILE_ID\n","Resolving docs.google.com (docs.google.com)... 142.251.2.100, 142.251.2.113, 142.251.2.138, ...\n","Connecting to docs.google.com (docs.google.com)|142.251.2.100|:443... connected.\n","HTTP request sent, awaiting response... 404 Not Found\n","2024-01-24 11:57:55 ERROR 404: Not Found.\n","\n","tar: This does not look like a tar archive\n","\n","gzip: stdin: unexpected end of file\n","tar: Child returned status 1\n","tar: Error is not recoverable: exiting now\n","[Errno 2] No such file or directory: 'CRF++-0.58'\n","/content\n","/bin/bash: line 1: ./configure: No such file or directory\n","/\n"]}]},{"cell_type":"code","metadata":{"id":"ibhkiIWrN_r1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706097477444,"user_tz":-540,"elapsed":1321,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}},"outputId":"f7a80483-d80b-4699-db0a-b3a5ce9faba9"},"source":["FILE_ID = \"0B4y35FiV1wh7SDd1Q1dUQkZQaUU\"\n","FILE_NAME = \"cabocha-0.69.tar.bz2\"\n","!wget --load-cookies /tmp/cookies.txt \"https://docs.google.com/uc?export=download&confirm=$(wget --quiet --save-cookies /tmp/cookies.txt --keep-session-cookies --no-check-certificate 'https://docs.google.com/uc?export=download&id=$FILE_ID' -O- | sed -rn 's/.*confirm=([0-9A-Za-z_]+).*/\\1\\n/p')&id=$FILE_ID\" -O $FILE_NAME && rm -rf /tmp/cookies.txt\n","!tar -xvf cabocha-0.69.tar.bz2\n","%cd cabocha-0.69\n","!./configure -with-charset=utf-8 && make && make check && make install && ldconfig\n","%cd .."],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["--2024-01-24 11:57:56--  https://docs.google.com/uc?export=download&confirm=&id=0B4y35FiV1wh7SDd1Q1dUQkZQaUU\n","Resolving docs.google.com (docs.google.com)... 142.251.2.100, 142.251.2.113, 142.251.2.138, ...\n","Connecting to docs.google.com (docs.google.com)|142.251.2.100|:443... connected.\n","HTTP request sent, awaiting response... 303 See Other\n","Location: https://drive.usercontent.google.com/download?id=0B4y35FiV1wh7SDd1Q1dUQkZQaUU&export=download [following]\n","--2024-01-24 11:57:56--  https://drive.usercontent.google.com/download?id=0B4y35FiV1wh7SDd1Q1dUQkZQaUU&export=download\n","Resolving drive.usercontent.google.com (drive.usercontent.google.com)... 142.251.2.132, 2607:f8b0:4023:c0d::84\n","Connecting to drive.usercontent.google.com (drive.usercontent.google.com)|142.251.2.132|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 2421 (2.4K) [text/html]\n","Saving to: ‘cabocha-0.69.tar.bz2’\n","\n","cabocha-0.69.tar.bz 100%[===================>]   2.36K  --.-KB/s    in 0s      \n","\n","2024-01-24 11:57:56 (40.7 MB/s) - ‘cabocha-0.69.tar.bz2’ saved [2421/2421]\n","\n","bzip2: (stdin) is not a bzip2 file.\n","tar: Child returned status 2\n","tar: Error is not recoverable: exiting now\n","[Errno 2] No such file or directory: 'cabocha-0.69'\n","/\n","/bin/bash: line 1: ./configure: No such file or directory\n","/\n"]}]},{"cell_type":"code","metadata":{"id":"9Ktlkf65lFGm","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706097477444,"user_tz":-540,"elapsed":3,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}},"outputId":"b83888aa-65b1-4982-db87-7f019937f205"},"source":["!cabocha -f1 -o ai.ja.txt.parsed ai.ja.txt"],"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["/bin/bash: line 1: cabocha: command not found\n"]}]},{"cell_type":"code","metadata":{"id":"38mcB8ybXk9i","outputId":"b2e9b9cf-efe3-4440-b43a-c1978776571a","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706097477444,"user_tz":-540,"elapsed":2,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["!wc -l ./ai.ja.txt.parsed"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["wc: ./ai.ja.txt.parsed: No such file or directory\n"]}]},{"cell_type":"code","metadata":{"id":"KtdaY5GLXplO","outputId":"6e15ed66-f66c-4843-da31-f166b29ed781","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706097477898,"user_tz":-540,"elapsed":455,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["!head -15 ./ai.ja.txt.parsed"],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["head: cannot open './ai.ja.txt.parsed' for reading: No such file or directory\n"]}]},{"cell_type":"markdown","metadata":{"id":"yOdZTWoAJCop"},"source":["## 40. 係り受け解析結果の読み込み（形態素）\n","***\n","形態素を表すクラスMorphを実装せよ．このクラスは表層形（surface），基本形（base），品詞（pos），品詞細分類1（pos1）をメンバ変数に持つこととする．さらに，係り受け解析の結果（ai.ja.txt.parsed）を読み込み，各文をMorphオブジェクトのリストとして表現し，冒頭の説明文の形態素列を表示せよ．"]},{"cell_type":"code","metadata":{"id":"M_SHvAz4JGSI","executionInfo":{"status":"ok","timestamp":1706097492316,"user_tz":-540,"elapsed":450,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["class Morph:\n","  def __init__(self, morph):\n","    (surface, attr) = morph.split('\\t')\n","    attr = attr.split(',')\n","    self.surface = surface\n","    self.base = attr[6]\n","    self.pos = attr[0]\n","    self.pos1 = attr[1]"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["    このコードは、形態素解析の結果を扱うための Morph というクラスを定義しています。形態素解析は、自然言語の文を形態素と呼ばれる最小の意味を持つ単位に分割するプロセスです。\n","    このクラスは、形態素の表層形（surface）、基本形（base）、品詞（pos）、品詞細分類1（pos1）の情報を保持します。\n","\n","    以下に、このクラスの各属性についての説明を示します：\n","\n","    surface: 形態素の表層形（surface form）を保持する属性です。\n","    base: 形態素の基本形（base form）を保持する属性です。基本形は、単語の原型や辞書形を指します。\n","    pos: 形態素の品詞（part of speech）を保持する属性です。品詞は単語の文法的な役割を示します。\n","    pos1: 形態素の品詞細分類1（part of speech sub-category 1）を保持する属性です。品詞細分類1は品詞を更に詳細に分類したものです。\n","\n","    このクラスは、形態素解析の結果から得られた情報を効果的に取り出し、オブジェクトとして保持するためのものです。\n","    例えば、形態素解析の結果が与えられた際に、それを Morph クラスのインスタンスとして扱うことができます。"],"metadata":{"id":"eqH1uhyMVuLV"}},{"cell_type":"code","source":["class Morph:\n","  def __init__(self, morph):\n","    # タブ文字が含まれていない場合は処理をスキップ\n","    if '\\t' not in morph:\n","      return\n","\n","    (surface, attr) = morph.split('\\t')\n","    attr = attr.split(',')\n","    self.surface = surface\n","    self.base = attr[6]\n","    self.pos = attr[0]\n","    self.pos1 = attr[1]\n"],"metadata":{"id":"29WL4tCWX5Nj","executionInfo":{"status":"ok","timestamp":1706098137675,"user_tz":-540,"elapsed":397,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","metadata":{"id":"24XgQwd8rqZi","outputId":"27256298-40e2-4ded-c835-09ccc8591b92","colab":{"base_uri":"https://localhost:8080/","height":250},"executionInfo":{"status":"error","timestamp":1706098172491,"user_tz":-540,"elapsed":436,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["filename = './ai.ja.txt.parsed'\n","\n","sentences = []\n","morphs = []\n","with open(filename, mode='r') as f:\n","  for line in f:\n","    if line[0] == '*':  # 係り受け関係を表す行：スキップ\n","      continue\n","    elif line != 'EOS\\n':  # 文末以外：Morphを適用し形態素リストに追加\n","      morphs.append(Morph(line))\n","    else:  # 文末：形態素リストを文リストに追加\n","      sentences.append(morphs)\n","      morphs = []\n","\n","# 確認\n","for m in sentences[2]:\n","  print(vars(m))"],"execution_count":36,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: './ai.ja.txt.parsed'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-36-c35dcbdf99cd>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msentences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmorphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'*'\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 係り受け関係を表す行：スキップ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ai.ja.txt.parsed'"]}]},{"cell_type":"markdown","metadata":{"id":"dUQQRQNKJHFB"},"source":["## 41. 係り受け解析結果の読み込み（文節・係り受け）\n","***\n","40に加えて，文節を表すクラスChunkを実装せよ．このクラスは形態素（Morphオブジェクト）のリスト（morphs），係り先文節インデックス番号（dst），係り元文節インデックス番号のリスト（srcs）をメンバ変数に持つこととする．さらに，入力テキストの係り受け解析結果を読み込み，１文をChunkオブジェクトのリストとして表現し，冒頭の説明文の文節の文字列と係り先を表示せよ．本章の残りの問題では，ここで作ったプログラムを活用せよ．"]},{"cell_type":"code","metadata":{"id":"8HxE_Bm_JKAT","executionInfo":{"status":"ok","timestamp":1706097986903,"user_tz":-540,"elapsed":3,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["class Chunk():\n","  def __init__(self, morphs, dst):\n","    self.morphs = morphs\n","    self.dst = dst\n","    self.srcs = []\n","\n","\n","class Sentence():\n","  def __init__(self, chunks):\n","    self.chunks = chunks\n","    for i, chunk in enumerate(self.chunks):\n","      if chunk.dst not in [None, -1]:\n","        self.chunks[chunk.dst].srcs.append(i)"],"execution_count":16,"outputs":[]},{"cell_type":"code","metadata":{"id":"9pjCz_HGjka-","outputId":"6dad80d7-2de6-4053-bf35-a80b1a75fe1f","colab":{"base_uri":"https://localhost:8080/","height":250},"executionInfo":{"status":"error","timestamp":1706097986903,"user_tz":-540,"elapsed":3,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["filename = './ai.ja.txt.parsed'\n","\n","sentences = []\n","chunks = []\n","morphs = []\n","with open(filename, mode='r') as f:\n","  for line in f:\n","    if line[0] == '*':  # 係り受け関係を表す行：直前の文節の情報にChunkを適用し文節リストに追加 + 直後の文節の係り先を取得\n","      if len(morphs) > 0:\n","        chunks.append(Chunk(morphs, dst))\n","        morphs = []\n","      dst = int(line.split(' ')[2].rstrip('D'))\n","    elif line != 'EOS\\n':  # 文末以外：Morphを適用し形態素リストに追加\n","      morphs.append(Morph(line))\n","    else:  # 文末：直前の文節の情報にChunkを適用し文節リストに追加 + 文節リストにSentenceを適用し文リストに追加\n","      chunks.append(Chunk(morphs, dst))\n","      sentences.append(Sentence(chunks))\n","      morphs = []\n","      chunks = []\n","      dst = None\n","\n","# 確認\n","for chunk in sentences[2].chunks:\n","  print([morph.surface for morph in chunk.morphs], chunk.dst, chunk.srcs)"],"execution_count":17,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: './ai.ja.txt.parsed'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-b97296eeebb2>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmorphs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'*'\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 係り受け関係を表す行：直前の文節の情報にChunkを適用し文節リストに追加 + 直後の文節の係り先を取得\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ai.ja.txt.parsed'"]}]},{"cell_type":"markdown","metadata":{"id":"IThw6rp7JKlv"},"source":["## 42. 係り元と係り先の文節の表示\n","***\n","係り元の文節と係り先の文節のテキストをタブ区切り形式ですべて抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"]},{"cell_type":"code","metadata":{"id":"w_LOQfX9JNby","outputId":"321ee669-f2f6-4db8-f20d-8e1970b99312","colab":{"base_uri":"https://localhost:8080/","height":268},"executionInfo":{"status":"error","timestamp":1706097987300,"user_tz":-540,"elapsed":2,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["sentence = sentences[2]\n","for chunk in sentence.chunks:\n","  if int(chunk.dst) != -1:\n","    modifier = ''.join([morph.surface if morph.pos != '記号' else '' for morph in chunk.morphs])\n","    modifiee = ''.join([morph.surface if morph.pos != '記号' else '' for morph in sentence.chunks[int(chunk.dst)].morphs])\n","    print(modifier, modifiee, sep='\\t')"],"execution_count":18,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"list index out of range","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-18-10d87413efcd>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmorph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurface\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmorph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'記号'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmorph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodifiee\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmorph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurface\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmorph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'記号'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmorph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"markdown","metadata":{"id":"qGAZlv4jJN9Z"},"source":["## 43. 名詞を含む文節が動詞を含む文節に係るものを抽出\n","***\n","名詞を含む文節が，動詞を含む文節に係るとき，これらをタブ区切り形式で抽出せよ．ただし，句読点などの記号は出力しないようにせよ．"]},{"cell_type":"code","metadata":{"id":"rznfyS7-JQyY","outputId":"9cd4913e-f18f-4c27-b283-fe0b64bf655f","colab":{"base_uri":"https://localhost:8080/","height":250},"executionInfo":{"status":"error","timestamp":1706097988000,"user_tz":-540,"elapsed":3,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["sentence = sentences[2]\n","for chunk in sentence.chunks:\n","  if int(chunk.dst) != -1:\n","    modifier = ''.join([morph.surface if morph.pos != '記号' else '' for morph in chunk.morphs])\n","    modifier_pos = [morph.pos for morph in chunk.morphs]\n","    modifiee = ''.join([morph.surface if morph.pos != '記号' else '' for morph in sentence.chunks[int(chunk.dst)].morphs])\n","    modifiee_pos = [morph.pos for morph in sentence.chunks[int(chunk.dst)].morphs]\n","    if '名詞' in modifier_pos and '動詞' in modifiee_pos:\n","      print(modifier, modifiee, sep='\\t')"],"execution_count":19,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"list index out of range","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-f5e13c662278>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdst\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mmodifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmorph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurface\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmorph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'記号'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m''\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmorph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmodifier_pos\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmorph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmorph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"markdown","metadata":{"id":"F32od7KuJRTj"},"source":["## 44. 係り受け木の可視化\n","***\n","与えられた文の係り受け木を有向グラフとして可視化せよ．可視化には，係り受け木をDOT言語に変換し，Graphvizを用いるとよい．また，Pythonから有向グラフを直接的に可視化するには，pydotを使うとよい．"]},{"cell_type":"code","metadata":{"id":"UdXKne-F_r-r","executionInfo":{"status":"aborted","timestamp":1706097988000,"user_tz":-540,"elapsed":1,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["# 日本語表示用フォントのインストール\n","!apt install fonts-ipafont-gothic"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Fl3eKsWRJUQi","outputId":"44827867-295f-48ca-b3f5-c3eba1dba49e","colab":{"base_uri":"https://localhost:8080/","height":250},"executionInfo":{"status":"error","timestamp":1706097988441,"user_tz":-540,"elapsed":3,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["import pydot\n","from IPython.display import Image,display_png\n","from graphviz import Digraph\n","\n","sentence = sentences[2]\n","edges = []\n","for id, chunk in enumerate(sentence.chunks):\n","  if int(chunk.dst) != -1:\n","    modifier = ''.join([morph.surface if morph.pos != '記号' else '' for morph in chunk.morphs] + ['(' + str(id) + ')'])\n","    modifiee = ''.join([morph.surface if morph.pos != '記号' else '' for morph in sentence.chunks[int(chunk.dst)].morphs] + ['(' + str(chunk.dst) + ')'])\n","    edges.append([modifier, modifiee])\n","n = pydot.Node('node')\n","n.fontname = 'IPAGothic'\n","g = pydot.graph_from_edges(edges, directed=True)\n","g.add_node(n)\n","g.write_png('./ans44.png')\n","display_png(Image('./ans44.png'))"],"execution_count":20,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"list index out of range","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-20-254d106faf0c>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgraphviz\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDigraph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0medges\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"markdown","metadata":{"id":"3RS374uwJUtA"},"source":["## 45. 動詞の格パターンの抽出\n","***\n","今回用いている文章をコーパスと見なし，日本語の述語が取りうる格を調査したい． 動詞を述語，動詞に係っている文節の助詞を格と考え，述語と格をタブ区切り形式で出力せよ． ただし，出力は以下の仕様を満たすようにせよ．\n","\n","- 動詞を含む文節において，最左の動詞の基本形を述語とする\n","- 述語に係る助詞を格とする\n","- 述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる  \n","\n","\n","このプログラムの出力をファイルに保存し，以下の事項をUNIXコマンドを用いて確認せよ．\n","\n","- コーパス中で頻出する述語と格パターンの組み合わせ\n","- 「行う」「なる」「与える」という動詞の格パターン（コーパス中で出現頻度の高い順に並べよ）"]},{"cell_type":"code","metadata":{"id":"0AOyO1RmJfRn","executionInfo":{"status":"ok","timestamp":1706097988849,"user_tz":-540,"elapsed":2,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["with open('./ans45.txt', 'w') as f:\n","  for sentence in sentences:\n","    for chunk in sentence.chunks:\n","      for morph in chunk.morphs:\n","        if morph.pos == '動詞':  # chunkの左から順番に動詞を探す\n","          cases = []\n","          for src in chunk.srcs:  # 見つけた動詞の係り元chunkから助詞を探す\n","            cases = cases + [morph.surface for morph in sentence.chunks[src].morphs if morph.pos == '助詞']\n","          if len(cases) > 0:  # 助詞が見つかった場合は重複除去後辞書順にソートして出力\n","            cases = sorted(list(set(cases)))\n","            line = '{}\\t{}'.format(morph.base, ' '.join(cases))\n","            print(line, file=f)\n","          break"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"0K_B-TPuqJod","executionInfo":{"status":"ok","timestamp":1706097988849,"user_tz":-540,"elapsed":2,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["# 確認\n","!cat ./ans45.txt | sort | uniq -c | sort -nr | head -n 10"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"id":"oGhGRa3pGTxE","executionInfo":{"status":"ok","timestamp":1706097988849,"user_tz":-540,"elapsed":2,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["!cat ./ans45.txt | grep '行う' | sort | uniq -c | sort -nr | head -n 5"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"id":"ceyLnZYazORo","executionInfo":{"status":"ok","timestamp":1706097988849,"user_tz":-540,"elapsed":1,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["!cat ./ans45.txt | grep 'なる' | sort | uniq -c | sort -nr | head -n 5"],"execution_count":24,"outputs":[]},{"cell_type":"code","metadata":{"id":"c8VZcBYPzR5r","executionInfo":{"status":"ok","timestamp":1706097989319,"user_tz":-540,"elapsed":471,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["!cat ./ans45.txt | grep '与える' | sort | uniq -c | sort -nr | head -n 5"],"execution_count":25,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8EKLLG-AJpSR"},"source":["## 46. 動詞の格フレーム情報の抽出\n","***\n","45のプログラムを改変し，述語と格パターンに続けて項（述語に係っている文節そのもの）をタブ区切り形式で出力せよ．45の仕様に加えて，以下の仕様を満たすようにせよ．\n","\n","- 項は述語に係っている文節の単語列とする（末尾の助詞を取り除く必要はない）\n","- 述語に係る文節が複数あるときは，助詞と同一の基準・順序でスペース区切りで並べる"]},{"cell_type":"code","metadata":{"id":"ZC01E_eTJtuo","executionInfo":{"status":"ok","timestamp":1706097989320,"user_tz":-540,"elapsed":2,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["with open('./ans46.txt', 'w') as f:\n","  for sentence in sentences:\n","    for chunk in sentence.chunks:\n","      for morph in chunk.morphs:\n","        if morph.pos == '動詞':  # chunkの左から順番に動詞を探す\n","          cases = []\n","          modi_chunks = []\n","          for src in chunk.srcs:  # 見つけた動詞の係り元chunkから助詞を探す\n","            case = [morph.surface for morph in sentence.chunks[src].morphs if morph.pos == '助詞']\n","            if len(case) > 0:  # 助詞を含むchunkの場合は助詞と項を取得\n","              cases = cases + case\n","              modi_chunks.append(''.join(morph.surface for morph in sentence.chunks[src].morphs if morph.pos != '記号'))\n","          if len(cases) > 0:  # 助詞が1つ以上見つかった場合は重複除去後辞書順にソートし、項と合わせて出力\n","            cases = sorted(list(set(cases)))\n","            line = '{}\\t{}\\t{}'.format(morph.base, ' '.join(cases), ' '.join(modi_chunks))\n","            print(line, file=f)\n","          break"],"execution_count":26,"outputs":[]},{"cell_type":"code","metadata":{"id":"5feYFtdbqNQV","executionInfo":{"status":"ok","timestamp":1706097989320,"user_tz":-540,"elapsed":2,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["# 確認\n","!cat ./ans46.txt | head -n 10"],"execution_count":27,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Fb2rr3AaJxSQ"},"source":["## 47. 機能動詞構文のマイニング\n","***\n","動詞のヲ格にサ変接続名詞が入っている場合のみに着目したい．46のプログラムを以下の仕様を満たすように改変せよ．\n","\n","- 「サ変接続名詞+を（助詞）」で構成される文節が動詞に係る場合のみを対象とする\n","述語は「サ変接続名詞+を+動詞の基本形」とし，文節中に複数の動詞があるときは，最左の動詞を用いる\n","- 述語に係る助詞（文節）が複数あるときは，すべての助詞をスペース区切りで辞書順に並べる\n","- 述語に係る文節が複数ある場合は，すべての項をスペース区切りで並べる（助詞の並び順と揃えよ）\n","\n","このプログラムの出力をファイルに保存し，以下の事項をUNIXコマンドを用いて確認せよ．\n","\n","- コーパス中で頻出する述語（サ変接続名詞+を+動詞）\n","- コーパス中で頻出する述語と助詞パターン"]},{"cell_type":"code","metadata":{"id":"AYsuO52CJ09W","executionInfo":{"status":"ok","timestamp":1706097989320,"user_tz":-540,"elapsed":2,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["with open('./ans47.txt', 'w') as f:\n","  for sentence in sentences:\n","    for chunk in sentence.chunks:\n","      for morph in chunk.morphs:\n","        if morph.pos == '動詞':  # chunkの左から順番に動詞を探す\n","          for i, src in enumerate(chunk.srcs):  # 見つけた動詞の係り元chunkが「サ変接続名詞+を」で構成されるか確認\n","            if len(sentence.chunks[src].morphs) == 2 and sentence.chunks[src].morphs[0].pos1 == 'サ変接続' and sentence.chunks[src].morphs[1].surface == 'を':\n","              predicate = ''.join([sentence.chunks[src].morphs[0].surface, sentence.chunks[src].morphs[1].surface, morph.base])\n","              cases = []\n","              modi_chunks = []\n","              for src_r in chunk.srcs[:i] + chunk.srcs[i + 1:]:  # 残りの係り元chunkから助詞を探す\n","                case = [morph.surface for morph in sentence.chunks[src_r].morphs if morph.pos == '助詞']\n","                if len(case) > 0:  # 助詞を含むchunkの場合は助詞と項を取得\n","                  cases = cases + case\n","                  modi_chunks.append(''.join(morph.surface for morph in sentence.chunks[src_r].morphs if morph.pos != '記号'))\n","              if len(cases) > 0:  # 助詞が1つ以上見つかった場合は重複除去後辞書順にソートし、項と合わせて出力\n","                cases = sorted(list(set(cases)))\n","                line = '{}\\t{}\\t{}'.format(predicate, ' '.join(cases), ' '.join(modi_chunks))\n","                print(line, file=f)\n","              break"],"execution_count":28,"outputs":[]},{"cell_type":"code","metadata":{"id":"Xm3PFSVeqObX","executionInfo":{"status":"ok","timestamp":1706097989748,"user_tz":-540,"elapsed":430,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["# 確認\n","!cat ./ans47.txt | cut -f 1 | sort | uniq -c | sort -nr | head -n 10"],"execution_count":29,"outputs":[]},{"cell_type":"code","metadata":{"id":"pBj7j6C3zZYK","executionInfo":{"status":"ok","timestamp":1706097989748,"user_tz":-540,"elapsed":4,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["!cat ./ans47.txt | cut -f 1,2 | sort | uniq -c | sort -nr | head -n 10"],"execution_count":30,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HcsfYnb3J7ug"},"source":["## 48. 名詞から根へのパスの抽出\n","***\n","文中のすべての名詞を含む文節に対し，その文節から構文木の根に至るパスを抽出せよ． ただし，構文木上のパスは以下の仕様を満たすものとする．\n","\n","- 各文節は（表層形の）形態素列で表現する\n","- パスの開始文節から終了文節に至るまで，各文節の表現を” -> “で連結する"]},{"cell_type":"code","metadata":{"id":"MnNqs7PkKDeX","outputId":"dad7ab1c-44ee-4686-cb0e-9c539b389903","colab":{"base_uri":"https://localhost:8080/","height":250},"executionInfo":{"status":"error","timestamp":1706097989748,"user_tz":-540,"elapsed":3,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["sentence = sentences[2]\n","for chunk in sentence.chunks:\n","  if '名詞' in [morph.pos for morph in chunk.morphs]:  # chunkが名詞を含むか確認\n","    path = [''.join(morph.surface for morph in chunk.morphs if morph.pos != '記号')]\n","    while chunk.dst != -1:  # 名詞を含むchunkを先頭に、dstを根まで順に辿ってリストに追加\n","      path.append(''.join(morph.surface for morph in sentence.chunks[chunk.dst].morphs if morph.pos != '記号'))\n","      chunk = sentence.chunks[chunk.dst]\n","    print(' -> '.join(path))"],"execution_count":31,"outputs":[{"output_type":"error","ename":"IndexError","evalue":"list index out of range","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-31-1bea6bd1550b>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentence\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m'名詞'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmorph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmorph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# chunkが名詞を含むか確認\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmorph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msurface\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmorph\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmorphs\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmorph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m'記号'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdst\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# 名詞を含むchunkを先頭に、dstを根まで順に辿ってリストに追加\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mIndexError\u001b[0m: list index out of range"]}]},{"cell_type":"markdown","metadata":{"id":"yjhsCjkrKDry"},"source":["## 49. 名詞間の係り受けパスの抽出\n","***\n","文中のすべての名詞句のペアを結ぶ最短係り受けパスを抽出せよ．ただし，名詞句ペアの文節番号がiとj（i<j）のとき，係り受けパスは以下の仕様を満たすものとする．\n","\n","- 問題48と同様に，パスは開始文節から終了文節に至るまでの各文節の表現（表層形の形態素列）を” -> “で連結して表現する\n","- 文節iとjに含まれる名詞句はそれぞれ，XとYに置換する\n","\n","また，係り受けパスの形状は，以下の2通りが考えられる．\n","\n","- 文節iから構文木の根に至る経路上に文節jが存在する場合: 文節iから文節jのパスを表示\n","- 上記以外で，文節iと文節jから構文木の根に至る経路上で共通の文節kで交わる場合: 文節iから文節kに至る直前のパスと文節jから文節kに至る直前までのパス，文節kの内容を” | “で連結して表示"]},{"cell_type":"code","metadata":{"id":"aj7rESZ8KOR5","executionInfo":{"status":"aborted","timestamp":1706097989748,"user_tz":-540,"elapsed":2,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"source":["from itertools import combinations\n","import re\n","\n","sentence = sentences[2]\n","nouns = []\n","for i, chunk in enumerate(sentence.chunks):\n","  if '名詞' in [morph.pos for morph in chunk.morphs]:  # 名詞を含む文節を抽出\n","    nouns.append(i)\n","for i, j in combinations(nouns, 2):  # 名詞を含む文節のペアごとにパスを作成\n","  path_i = []\n","  path_j = []\n","  while i != j:\n","    if i < j:\n","      path_i.append(i)\n","      i = sentence.chunks[i].dst\n","    else:\n","      path_j.append(j)\n","      j = sentence.chunks[j].dst\n","  if len(path_j) == 0:  # 1つ目のケース\n","    chunk_X = ''.join([morph.surface if morph.pos != '名詞' else 'X' for morph in sentence.chunks[path_i[0]].morphs])\n","    chunk_Y = ''.join([morph.surface if morph.pos != '名詞' else 'Y' for morph in sentence.chunks[i].morphs])\n","    chunk_X = re.sub('X+', 'X', chunk_X)\n","    chunk_Y = re.sub('Y+', 'Y', chunk_Y)\n","    path_XtoY = [chunk_X] + [''.join(morph.surface for morph in sentence.chunks[n].morphs) for n in path_i[1:]] + [chunk_Y]\n","    print(' -> '.join(path_XtoY))\n","  else:  # 2つ目のケース\n","    chunk_X = ''.join([morph.surface if morph.pos != '名詞' else 'X' for morph in sentence.chunks[path_i[0]].morphs])\n","    chunk_Y = ''.join([morph.surface if morph.pos != '名詞' else 'Y' for morph in sentence.chunks[path_j[0]].morphs])\n","    chunk_k = ''.join([morph.surface for morph in sentence.chunks[i].morphs])\n","    chunk_X = re.sub('X+', 'X', chunk_X)\n","    chunk_Y = re.sub('Y+', 'Y', chunk_Y)\n","    path_X = [chunk_X] + [''.join(morph.surface for morph in sentence.chunks[n].morphs) for n in path_i[1:]]\n","    path_Y = [chunk_Y] + [''.join(morph.surface for morph in sentence.chunks[n].morphs) for n in path_j[1:]]\n","    print(' | '.join([' -> '.join(path_X), ' -> '.join(path_Y), chunk_k]))"],"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"eVbsa7tCXVN5","executionInfo":{"status":"aborted","timestamp":1706097989748,"user_tz":-540,"elapsed":2,"user":{"displayName":"Chani Leon","userId":"10653674807294340789"}}},"execution_count":null,"outputs":[]}]}